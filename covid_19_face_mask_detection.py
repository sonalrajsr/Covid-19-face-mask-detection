# -*- coding: utf-8 -*-
"""Covid 19 Face Mask detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_TXRH0LVboUedFVilRWgLd6iiReTrAfS

Important Libraries
"""

import os
import random
import cv2
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from keras.applications.vgg16 import VGG16
from keras import Sequential

"""**Example images of dataset**"""

def display_images(path, title):
  file_list = os.listdir(path)
  print("Total Images are: ", len(file_list))
  fig = plt.figure(figsize = (10,5))
  for index in range(5):
    image_path = os.path.join(path, file_list[random.randint(0, len(file_list))])
    img = mpimg.imread(image_path)
    ax = fig.add_subplot(1, 5, index+1)
    ax.imshow(img)
    ax.axis('off')
  plt.suptitle(title)
  plt.show()

display_images("/content/drive/MyDrive/DataSet_ML/Covid-19-Multiclass-photos/with_mask","Images With Mask" )

display_images("/content/drive/MyDrive/DataSet_ML/Covid-19-Multiclass-photos/without_mask","Images Without Mask" )

"""Class of dataset"""

# 0 = No mask
# 1 = Having mask
Categories = [0, 1]

"""Creating list of features and class for model training"""

data = []
initial_path = "/content/drive/MyDrive/DataSet_ML/Covid-19-Multiclass-photos"
next_path = os.listdir(initial_path)
for i,label in enumerate(Categories):
  final_path = os.path.join(initial_path, next_path[i])
  for file in os.listdir(final_path):
    img_path = os.path.join(final_path, file)
    img = cv2.imread(img_path)
    img = cv2.resize(img, (224,224))
    data.append([img, label])

random.shuffle(data)

X = [] #Storing Images as features
Y = [] #Storing labels as 0, 1

for features, label in data:
  X.append(features)
  Y.append(label)
images = np.array(X)
images = images/255
labels = np.array(Y)

X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size = 0.2, random_state=42)

"""Using VGG16"""

vgg = VGG16()

vgg.summary()

#Removing last layer(Predictions) form VGG16
model = Sequential()
for layer in vgg.layers[:-1]:
  model.add(layer)

model.summary()

#Make rest parameters as non trainable
for layer in model.layers:
  layer.trainable = False

model.summary()

#Adding our last denser layer
from keras.layers import Dense
model.add(Dense(1, activation = 'sigmoid'))

model.summary()

model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

model.fit(X_train, y_train, epochs = 5, validation_data=(X_test, y_test))

"""Collab snipit for Using Camera"""

from IPython.display import display, Javascript
from google.colab.output import eval_js
from base64 import b64decode

def take_photo(filename='photo.jpg', quality=0.8):
  js = Javascript('''
    async function takePhoto(quality) {
      const div = document.createElement('div');
      const capture = document.createElement('button');
      capture.textContent = 'Capture';
      div.appendChild(capture);

      const video = document.createElement('video');
      video.style.display = 'block';
      const stream = await navigator.mediaDevices.getUserMedia({video: true});

      document.body.appendChild(div);
      div.appendChild(video);
      video.srcObject = stream;
      await video.play();

      // Resize the output to fit the video element.
      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

      // Wait for Capture to be clicked.
      await new Promise((resolve) => capture.onclick = resolve);

      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext('2d').drawImage(video, 0, 0);
      stream.getVideoTracks()[0].stop();
      div.remove();
      return canvas.toDataURL('image/jpeg', quality);
    }
    ''')
  display(js)
  data = eval_js('takePhoto({})'.format(quality))
  binary = b64decode(data.split(',')[1])
  with open(filename, 'wb') as f:
    f.write(binary)
  return filename

from IPython.display import Image
try:
  filename = take_photo()
  print('Saved to {}'.format(filename))
  test = cv2.imread(filename)
  test = cv2.resize(test, (224,224))
  test = test.reshape((1, 224, 224, 3))
  predict = model.predict(test)
  if predict < 0.5:
    print("No Mask")
  else:
    print("With Mask")
  print("Possibility of having mask",predict)
  # Show the image which was just taken.
  display(Image(filename))
except Exception as err:
  # Errors will be thrown if the user does not have a webcam or if they do not
  # grant the page permission to access it.
  print(str(err))

from IPython.display import Image
try:
  filename = take_photo()
  print('Saved to {}'.format(filename))
  test = cv2.imread(filename)
  test = cv2.resize(test, (224,224))
  test = test.reshape((1, 224, 224, 3))
  predict = model.predict(test)
  if predict < 0.5:
    print("No Mask")
  else:
    print("With Mask")
  print("Possibility of having mask",predict)
  # Show the image which was just taken.
  display(Image(filename))
except Exception as err:
  # Errors will be thrown if the user does not have a webcam or if they do not
  # grant the page permission to access it.
  print(str(err))